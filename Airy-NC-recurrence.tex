\documentclass{amsart}
\usepackage{amscd,amsmath,amsthm,amssymb}
\usepackage{enumerate,varioref}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{mathtools}
\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\theoremstyle{remark}
\newtheorem{ex}[thm]{Example}
\newtheorem{rem}[thm]{Remark}
\numberwithin{equation}{section}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\lrbrack}[2]{\lbrack #1 , #2 \rbrack}
\newcommand{\wbc}[3]{\left\{\begin{array}{cc}
		{#1}\\{#2}
	\end{array} \right\}_{#3}}
\newcommand{\cc}[3]{{#1}!{#2 \choose #1}{#3 \choose #1}}
%\cc is for commutator constants
\newcommand{\half}{\frac{1}{2}}
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle #1 |}


\title{The solution to Airy's equation via a noncommutative recurrence relation.}
\author{GCA}

\begin{document}
\maketitle


\section{Introduction}

The main motivation to solving Airy's equation is that it is one amongst the simplest nontrivial differential equations of the form
\[
d^n y = x^m y + \lambda y
\]

When $n$ is one, this is a simple first order equation.  The special case when $n=m=2$ is the well known quantum harmonic oscillator.  Airy's equation ($n=2,m=1$) is of interest drawing from it's application in astronomy, but because when $x<0$ we have an oscillatory solution, but asymptotically we have an exponential solution.  So we look to solving
\[
y'' = xy
\]

Here we expect to have a nontrivial kernel of the differential operator $d^2 - x$.  This will turn out to be a rather rare case, and thus it is worth our interest and effort.

The standard solution has two well-known linearly independent solutions pictured below.

%pics of airy's functions type 1 and 2.


\section{Airy's Equation}

Airy's equation in it's simplest form is given by
\[
y'' = xy.
\]


For most of our research, we will often wish to consider quantum mechanical systems, and thus we adopt the quantum style of writing differential equations with the function $\psi$.
\[
\psi'' = x\psi
\]





\section{The Standard Power Series Treatment}


The standard power series treatment assumes that we can write $\psi$ as a power series (McLaurin) in $x$.

\[
\psi(x) = \sum_{k=0}^{\infty} a_k x^k
\]


Now using our differential operator we simply differentiate term by term and collect terms on each power and set equal to zero.

\[
\frac{d^2}{dx^2}\sum_{k=0}^{\infty} a_k x^k = \sum_{k=0}^{\infty} k(k-1)a_k x^{k-2} = \sum_{k=0}^{\infty} (k+2)(k+1)a_{k+2} x^k
\]


On the other hand we have
\[
x\psi = x\sum_{k=0}^{\infty} a_k x_k = \sum_{k=0}^{\infty} a_k x^{k+1}
\]


Now we say these are equal as prescribed by the differential equation, collecting terms we see
\[
(k+2)(k+1)a_{k+2} = a_{k-1}
\]

Since this is a second order equation we have initial conditions $a_0 = \psi(0)$ and $a_1 = \psi'(0)$. We also assume $a_{-1}=0$.

Then we start working on recurrence relations.
\[
a_{k+2} = \frac{a_{k-1}}{(k+2)(k+1)} 
\]

From here can determine that $a_2=0$ otherwise, we have three linearly independent solutions which violates the index of the operator.  Thus we see we have two sets of relations:
\[
a_0,a_3,\dots, a_{3k} = \frac{a_0}{2\cdot 3\cdot 5\cdot 6 \cdots (3n-3)(3n-1)(3n)},\dots
\]

Where we skip $1\mod 3$ in the denominator product.  We also have

\[
a_1,a_4,\dots, a_{3k+1} = \frac{a_1}{3\cdot 4 \cdot 6\cdot 7\cdots (3n-2)(3n)(3n+1)}
\]



Reducing we come up with two solutions $Ai_1$ and $Ai_2$ and our general solution is
\[
\psi(x) = a_0 Ai_1(x) + a_1 Ai_2(x).
\]

These linearly independent solutions are called Airy functions of the first and second type.



\section{The Taylor Series Approach}


The solution to Airy's equation in the power series approach amounts to equating coefficients of a polynomial.  In the Taylor series approach we rely on the differential equation much more heavily.  For example we write
\[
\psi(x) = \sum_{k=0}^{\infty} \psi^{(k)}(a) \frac{(x-a)^k}{k!}
\]


Where
\[
\psi^{(k)}(x) = \frac{d^k}{dx^k}\psi(x).
\]

In our case, we will take the Kovalesky style approach and simply keep taking derivatives and simplifying to reach the next derivative.  For example, we assume that we know $\psi(a)$ and $\psi'(a)$ and we know
\[
\psi''(a) = a\psi(a)
\]
as required by the differential equation.

Now consider the third derivative
\[
\psi'''(x) = d\psi''(x) = d(x\psi(x)) = \psi(x)+ x\psi'(x)
\]


Moving one derivative further we have
\[
\psi^{(4)}(x) = d(\psi'''(x)) = d(\psi + x\psi') = \psi' + \psi' +x\psi'' = x^2 \psi + 2\psi'
\]


In this way we see that each derivative will have either $\psi$ and $\psi'$.  Thus we can restate the Taylor series by
\[
\psi^{(n)} = f_n \psi + g_n \psi'
\]

Thus
\[
\sum_n \psi^{(n)}(a) \frac{(x-a)^n}{n!} = \sum_n [f_n(a) \psi(a)+g_n(a)\psi'(a)]\frac{(x-a)^n}{n!}
\]

Which suggests that we now have two linearly independent power series, but the $f_n$ and $g_n$ are the coefficients of the exponential generating functions of Airy functions of type 1 and type 2 respectively.


In other words
\[
Ai_1(x) = \psi(a) \sum_n f_n(a)\frac{(x-a)^n}{n!} 
\]

\[
Ai_2(x) = \psi'(a) \sum_n g_n(a)\frac{(x-a)^n}{n!}
\]

\section{Moving to a Noncommutative Recurrence}

If we are to solve the Airy equation, we must see if we can first solve for the $f_n$ and $g_n$ as written above.

Looking at our relations between consecutive derivatives of $\psi$ we see

\[
\psi^{(n)} = f_n \psi + g_n \psi'
\]

Then taking one derivative

\[
\psi^{(n+1)} = f_{n+1}\psi + g_{n+1}\psi' = f_n' \psi + f_n \psi' + g_n' \psi' + g_n \psi''
\]

Now using our relation
\[
\psi'' = x\psi
\]
and collecting terms we see

\[
f_{n+1} = f_n'+xg_n, \text{ and } g_{n+1} = f_n + g_n'
\]


In terms of a recurrence relation we can write this as
\begin{equation}
\begin{bmatrix}
f_{n+1} \\ g_{n+1} 
\end{bmatrix} = \begin{bmatrix}
d & x\\ 
1 & d
\end{bmatrix}
\begin{bmatrix}
f_n \\ g_n
\end{bmatrix}
\end{equation}

It now becomes our goal to find the powers of this matrix
\[
M= \begin{bmatrix}
d & x\\1 & d
\end{bmatrix}
\]

\subsection{The First Solution Method}

In this particular case we will try to solve this by induction.  Since matrix multiplication is associative (even in the case where the elements are in a noncommutative ring) We know that
\[
M^{n+1} = M^n M = M M^n
\]

So by assumption we guess that 
\[
M^n = \begin{bmatrix}
q & r\\
s & t
\end{bmatrix}
\]
where $q,r,s,t$ are polynomials in $x$ and $d$.  Of course, we prefer to keep the ``normal" ordering which is to say all $x$ to the left of all $d$. This, of course, comes from the fact that $df = 0$ has a nontrivial solution whereas $xf=0$ has only the trivial solution.

Writing down our equation we have
\[
\begin{bmatrix}
d & x\\
1 & d
\end{bmatrix} 
\begin{bmatrix}
q & r\\
s & t
\end{bmatrix}=
\begin{bmatrix}
q & r\\
s & t
\end{bmatrix}
\begin{bmatrix}
d & x\\
1 & d
\end{bmatrix} 
\]


Equating the entries we get
\begin{itemize}
\item[(11)] $dq + xs = qd + r$\\
\item[(12)] $dr + xt = qx + rd$\\
\item[(21)] $q + ds = sd + t$\\
\item[(22)] $r + dt = sx + td$
\end{itemize}



This leads us to the reduced equations\\



\begin{itemize}
\item[(11)] $[d,q] =  r -xs$\\
\item[(12)] $[d,r] = qx -xt$\\
\item[(21)] $[d,s] = t-q $\\
\item[(22)] $[d,t] = sx -r$
\end{itemize}


Here, we run into the problem that $q_n$ and $t_n$ are no longer equal after $n>2$.  However, each piece will certainly carry a copy of $d^n$.  Now let's see if we can reduce these equations a little more.  We have Jacobi's identity:
\[
[A,[B,C]] + [B,[C,A]] + [C,[A,B]] = 0
\]

This tells us:
\[
[d,[a,x]] + [a[d,x]]+[x,[a,d]] = 0 \implies [d,[a,x]] = [[d,a],x]
\]
This means we can shift the brackets to make them convenient to our liking.





\subsection{The Second Solution Method}


Let's examine our matrix $M$ again and write it as a sum of matrices.
\[
M = A + B = \begin{bmatrix}
d & 0\\
0 & d
\end{bmatrix} + 
\begin{bmatrix}
0 & x\\
1 & 0
\end{bmatrix}
\]

In this case we try to compute $M^n$ using a binomial theorem on noncommuting variables.

\[
(A+B)^2 = A^2 + AB + BA + B^2 
\]

We'll adopt our ``normal ordering" convention, where $x$ sits the the left of $d$, and so we write:

\[
(A+B)^2 = B^2 + 2BA + A^2 + [A,B]
\]

In this case we need to know commutators of $A,B,[A,B],[A,[A,B]],[B,[A,B]],\dots$


In our case this simplifies nicely, since, we zero out after four steps.

\[
[A,B] = C = \begin{bmatrix}
0 & 1\\ 0 & 0
\end{bmatrix}
\]

Notice that $C^2=0$.

Furthermore We see that $A$ which is diagonal (and a constant multiple of $I$) commutes with constant matrices so
\[
[A,C] = 0.
\]

Now let's check on $[B,C]$

\[
[B,C] = \begin{bmatrix}
-1 & 0\\
0 & 1
\end{bmatrix} = h
\]

We call this $h$ in reference to the Cartan element from $sl_2$.


With this reference to $sl_2$ we can see
\[
[B,h] = -2B
\]

finally we consider 
\[
[C,h] = 2C
\]

And hence we have a set of all the matrices we must consider:
\[
A=\begin{bmatrix}
d & 0\\
0 & d
\end{bmatrix},
B=\begin{bmatrix}
0 & x\\
1 & 0
\end{bmatrix},
C = \begin{bmatrix}
0 & 1\\
0 & 0
\end{bmatrix},
h = \begin{bmatrix}
-1 & 0\\
0 & 1
\end{bmatrix}
\]


We also have a short list of additional helpful relations:

\begin{itemize}
\item[i] $[A,C] = 0$\\
\item[ii] $[A,h] = 0$\\
\item[iii] $Bh+hB = 0$\\
\item[iv] $Ch+hC = 0$\\
\item[v] $[A^n,B]=nA^{n-1}C$\\
\item[vi] $[A,B^n] = nB^{n-1}C - \binom{n}{2}B^{n-2}h - 2\binom{n}{3}B^{n-2}$\\
\item[vii] $[B^2,C]=0$\\
\item[viii] $[B^2,h]=0$\\
\item[ix] $C^2=0$\\
\item[x] $h^2=I$
\end{itemize}


\begin{rem}
A quick side note on item vi.  In order to solve this I simply guessed a solution knowing the $nB^{n-1}C$ would certainly come up.  I guessed the rest to be some matrix $Q$.  I commuted $Q$ with an additional power of $B$ until I got more terms.  Since the derived series is finite (i.e. $[[[A,B],B],B]=0$) I wrote down a sequence where I gave coefficients to each term and solved these by induction.  The equations ended up returning to nonhomogeneous recurrence relations.  

An additional side remark within a side remark.  I had trouble solving the final term $2\binom{n}{3}$ at first and so I tried to solve it using a generating function.  That approach yielded the following differential equation:
\[
x^3 f'' = (x-1)f.
\]
This is more difficult than solving the Airy equation, and so I went back to old methods and found the solution fairly quickly.

\end{rem}

For this calculation we must choose a ``normal ordering."  Certainly we prefer $B$ then $A$ since $A$ has a nontrivial kernel where $B$ does not.  $C$ has the largest nontrivial kernel, so it should come to the right of $A$ and the matter of $h$ is somewhat less important since $h^2=I$.  Thus we will consider our ``normal ordering" in this case to be
\[
B^i A^j \text{ or } B^i A^j C \text{ or } B^iA^jh \text{ or } B^iA^jCh
\]


In order to get through a calculation of the form $(A+B)^n$ we will employ a few more techniques that we know from the quantum harmonic oscillator algebra.  First of all, observe:
\[
B^2 = x\cdot I  \implies B^{2n} = x^n \cdot I
\]

Then we have
\[
[A^n,B^{2m}] = \begin{bmatrix}
[d^n,x^m] & 0 \\
0 & [d^n,x^m]
\end{bmatrix}.
\]

Which we know how to compute.  Recall the formula: if $[a,b]=1$ then

\[
[a^n,b^m] = \sum_{j=1}^{\min(n,m)} j!\binom{n}{j}\binom{m}{j}b^{m-j}a^{n-j}
\]

This is ``easily" proven by induction on two variables.


Now let's see if we can solve this overall commutator by induction.

Suppose we know
\[
(A+B)^n = \sum c^n_{ijk\ell} B^i A^j C^k h^{\ell}
\]

Here we know $k=0,1$ and $\ell = 0,1$.  So we can split this into four pieces. 
\[(k,\ell) = (0,0),(0,1),(1,0),(1,1)\]

In every case, the $A$ term passes through $C$ and $h$ since these all commute.  Additionally, $Ch = C$ So the case of $(1,1)$ is identical to the case $(1,0)$.  We need only to consider the following cases:

\[
B^i A^j B = B^{i+1}A^j + jB^i A^{j-1}C
\]

Second, we have 

\[
B^i A^j C B = B^i A^j (BC-h) = (B^iA^jB)C - B^i A^j h 
\]

The term in brackets $B^iA^jB$ was computed above and its second term produces a copy of $C$ but $C^2=0$ so we're left simply with:

\[
B^i A^j C B = B^{i+1}A^j C - B^i A^j h
\]

Finally we have 

\[
B^i A^j h B = B^i A^j (B(h+2)) = B^{i+1}A^j (h+2) + jB^iA^{j-1}(h+2)
\]





\end{document}
